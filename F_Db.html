                <!--dev/F#/F_Db content-->
                <section>
                    <div id="F_Db">
<center><img src='https://th.bing.com/th/id/R.e8313479d3ee7fec5bbea87b04bd14d3?rik=ElKg%2f4FSInzOeg&riu=http%3a%2f%2finfo.mongodb.com%2frs%2fmongodb%2fimages%2fMongoDB_Logo_Full.png&ehk=LcPlgoPKxq3Xi3COif0NcttyOV4gnYAVlxFefj%2fJcdY%3d&risl=&pid=ImgRaw&r=0'></center>
<br>
Mongo <a href='https://www.mongodb.com/docs/drivers/csharp/current/'>dotNet</a> driver docs
<br>
    The MongoDB Developer <a href='https://developer.mongodb.com/community/forums/'>Hub</a>
<hr>
Playground: 
<ul><li><a href='https://mongoplayground.net/p/BgVQu0U_ZO5'>Grp</a>, Select distinct and count</li>
<li>Sample dat w/<a href='https://mongoplayground.net/p/YRZhxBjDTVp'>tags</a>
</li></ul>

<hr>
<p>
<details>
<summary><span class='mHG'>JSon</span></summary>
<ul><li>
Mongo (v2) <a href='https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/'>Extended</a> json
</li><li>Extended JSon <a href='https://github.com/mongodb/specifications/blob/master/source/extended-json.rst#canonical-extended-json-example'>spec</a>
</li><li>
<i>Canonical Mode: A string format that emphasizes type preservation at the expense of readability and interoperability</i>
</li><li>
How to serialize and deserialize (marshal and unmarshal) <a href='https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/how-to?pivots=dotnet-7-0'>JSON</a> in .NET
</li><li>
<b>Note:</b>
<br>If you wish to insert array of JSON objects at once, where each array entry shall be treated as separate dtabase entry, you have two options of syntax:
<br>Array of object with valid coma positions & --jsonArray flag obligatory
<code><pre>
[
  {obj1},
  {obj2},
  {obj3}
]
</pre></code>
Use file with <b>basically incorrect</b> JSON formatting (i.e. missing , between JSON object instances & without --jsonArray flag
<code><pre>
{obj1}
{obj2}
{obj3}
</pre></code>
</li><li><a href='https://learn.microsoft.com/en-us/dotnet/api/system.text.json.utf8jsonwriter.writeboolean?view=net-7.0'>Utf8JsonWriter</a> is a high-performance way to write UTF-8 encoded JSON text from common .NET types like String, Int32, and DateTime. The writer is a low-level type that can be used to build custom serializers. The JsonSerializer.Serialize method uses Utf8JsonWriter under the covers.
<br><b>Usage</b>: Utf8JsonWriter.writeBoolean/Number/String(tg, val)
<br><b>snippet</b>:
<code><pre>
open System.Text.Json

    let toJson =
      fun inLi: ->

      use memStrm = new MemoryStream()
      use jWriter = new Utf8JsonWriter(memStrm, new JsonWriterOptions(Indented = true))

        //match on DFldTy here...
        lim (fun r -> 
      let (ty, nm, dat) = r
      writer.WriteStartObject()
      match ty with 
      |  -> 	writer.WriteString("date", DateTimeOffset.UtcNow)
      |  -> 	writer.WriteNumber("temp", 42)
      |  -> 	writer.WriteBoolean("bool", true)
      | _ -> 	printfn "Unknown ty encountered"
      writer.WriteEndObject()
      ) inLi |> ignore

    writer.Flush()

    Console.WriteLine(Encoding.UTF8.GetString(stream.ToArray()))
</pre></code>
</li><li>
<br>BSON Ext <a href='https://github.com/mongodb-js/bson-ext'>parser</a><b>snippet</b>:
<code><pre>
module BSonExt

    //@ToDo: chk if contents curr use '==' delims
    fun toBE = match
          | Dt -> 
                Def -> preComp -> Driver
                preComp cTor w/Def?
                lifo (getAll ~) mods + (get DefFlds)
          | Dz -> hardCoded
              
    fun frBE = Def -> BTy -> Dat
</pre></code>
</li></ul>
</details>
<p>
<details>
<summary><span class='mHG'>Importing to Mongo</span></summary>
<a href='https://www.mongodb.com/docs/database-tools/mongoimport/#mongodb-binary-bin.mongoimport'>mongoimport</a> docs
    max batch size of 100k to perform bulk insert/upsert operations
<br>
-f=&lt;field1[,field2]&gt;<br>
Specify a comma separated list of field names when importing CSV/TSV
 files that do not have field names in the first (i.e. header) line of the file.
<br>
To also specify the field type as well as the field name, use 
--fields  with <a href='https://www.mongodb.com/docs/database-tools/mongoimport/#std-option-mongoimport.--columnsHaveTypes'>--columnsHaveTypes</a>.
<br>
C# <a href='https://www.mongodb.com/docs/drivers/csharp/current/fundamentals/data-formats/poco/#std-label-csharp-custom-serialization'>custom</a> serialization uses attribs to control exactly how the POCO 2 BSON is done
<br>
<b>ID</b>: By default, the driver maps any public property named Id, id, or _id to the BSON _id field.
<br>
Example: <b>Importing</b> for local debugging 
(compatible with <a href='https://github.com/Mongo2Go/Mongo2Go'>ASP.NET MVC</a> 4 Web API as well as ASP.NET Core)


<br>How to serialize and deserialize (marshal and unmarshal) <a href='https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/how-to?pivots=dotnet-7-0'>JSON</a> in .NET

<br>Mongo: Work with <a href='https://www.mongodb.com/docs/drivers/csharp/current/fundamentals/data-formats/poco/#std-label-csharp-poco'>POCOs</a>

<br>BSON <a href='https://github.com/mongodb-js/bson-ext'>Ext</a> parser

<details>
<summary><span class='mHG'>Note on direct JSon importing (SO)</span></summary>
If you wish to insert array of JSON objects at once, where each array entry shall be treated as separate dtabase entry, you have two options of syntax:

<br>Array of object with valid coma positions & --jsonArray flag obligatory
<code><pre>
[
  {obj1},
  {obj2},
  {obj3}
]
</pre></code>
<br>Use file with basically <b>incorrect</b> JSON formatting (i.e. missing , between JSON object instances & without --jsonArray flag
<code><pre>
{obj1}
{obj2}
{obj3}
</pre></code>
<hr></details>

<hr></details>
 
<p>
<details>
<summary><span class='mHG'>Serialization</span></summary>
<ul><li>
Mongo: Work with <a href='https://www.mongodb.com/docs/drivers/csharp/current/fundamentals/data-formats/poco/#std-label-csharp-poco'>POCOs</a>
</li><li>
C# import <a href='https://www.mongodb.com/docs/guides/crud/insert/'>example</a>
<br>(No way to indicate fld type from a CSV dump; let the mongo driver autoChk from class) 
</li><li>
C# <a href='https://www.mongodb.com/docs/drivers/csharp/current/fundamentals/data-formats/poco/#std-label-csharp-custom-serialization'>custom</a> serialization uses attribs to control exactly how the POCO 2 BSON is done
</li><li>
By default, the driver maps any public property named Id, id, or _id to the BSON _id field.
</li></ul>
Writing a <a href='https://stackoverflow.com/questions/42915080/is-writing-a-discriminated-union-to-mongodb-possible'>DU</a> ty to Mongo
<ul><li>
1 way we mt have to go is to write a manual ser/Deser FOR customType as you wd w/any serializer, e.g. <a href='https://github.com/NamelessInteractive/NamelessInteractive.FSharp/blob/master/NamelessInteractive.FSharp.MongoDB/DiscriminatedUnionSerializer.fs'>here</a>
<br>
BASICALLY this file + this one: FSharpSerializationProvider.fs
contains all that's necc to provide a custom de/ser frm/to Mongo
</li><li>
MongoDox <a href='https://mongodb.github.io/mongo-csharp-driver/2.4/reference/bson/serialization/'>custom</a> ser info<br>
also srch this pg for "TryGetMemberSerializationInfo"<br>
</li>
NOTE that when everything's set up, on db.insert/etc. the system auto-ser/deser the obs.
<li>
<br>
The .NET BSON library supports mapping Custom classes to and from BSON/JSON using a <a href='https://mongodb.github.io/mongo-csharp-driver/2.4/reference/bson/mapping/'>BsonClassMap</a>.
<br>
If you want to control the creation of the class map, you can provide your own initialization code in the form of a lambda expression:
<code><pre>
BsonClassMap.RegisterClassMap<MyClass>(cm => {
    cm.MapMember(c => c.SomeProperty);
    cm.MapMember(c => c.AnotherProperty); });
</pre></code>
</li>
<li>Good Overview of the process: BSON <a href='https://darkiri.wordpress.com/2013/02/26/bson-serialization-with-mongodb-c-driver/'>Serialization</a> with the MongoDB C# Driver
<br>Yes, both custom Serializers + ClassMaps are necc.
<br>Besides renaming (if nded via SetElementName) flds, ClassMaps allow NOT messing your types w/attributes et al.; this info is passed to Mongo via your mapping 
</li>
<li>
  See also this <a href='http://www.fssnip.net/7Qw/title/mongodb-map-immutable-record-constructor-adhoc-example'>fssnip example</a> 
  </li>
So basically we can create a BsonClassMap<Brij> & map the classDef to ea fldNm/ty<br>
Note that the ex is for a rec; we nd an alt way to prov fldNm<br>
<code><pre>
      cm.MapMember(c => c.SomeProperty).SetElementName("sp")</pre></code>
      (from the MongoDox link above)
<hr>
</details>  
<p>
<details>
<summary><span class='mHG'>Aggregation | Pipeline</span></summary>
    Mongodox
    <ul><li>
    List of <a href='https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/#alphabetical-listing-of-stages'>Stages</a>
    </li><li>
    MongoDB Aggregation Pipeline <a href='https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/'>Stages</a> reference
    </li><li>
    MongoDB Aggregation Pipeline <a href='https://docs.mongodb.com/manual/reference/operator/aggregation/'>Operators</a> reference
    </li><li>
    MongoDB Aggregation Stages <a href='https://www.practical-mongodb-aggregations.com/appendices/cheatsheet.html'>Cheatsheet</a>
    </li><li>
    MongoDB Aggregation Stages Cheatsheet <a href='https://www.practical-mongodb-aggregations.com/appendices/cheatsheet-source.html'>Source</a> Code
    </li></ul>

    <hr>


    <ul><li>
    How To Use <a href='https://www.digitalocean.com/community/tutorials/how-to-use-aggregations-in-mongodb'>Aggregations</a> in MongoDB<br>
    ($match instd of filter, multiple sorts, $project, $id w/multiple flds, calc. flds)
    </li><li>
    $unwind: if doc has an array fld: fldNm:[1,2,3] it creates 3 docs
       Therefore if we've used $$root & wish to split we can use this as a stage
    </li><li>
    $facet: used to apply multiple aggregation stages in a single pipeline stage.
    </li><li>
    $replaceRoot: You can <a href='https://www.mongodb.com/docs/manual/reference/operator/aggregation/replaceRoot/#mongodb-pipeline-pipe.-replaceRoot'>promote</a> an existing embedded document to the top level, or create a new document for promotion
    </li><li>
    $function : supports customized transformations
    </li><li>
    (SO <a href='https://stackoverflow.com/questions/70839664/how-to-write-this-mongodb-aggregate-query-into-c-sharp'>Qn</a>)
    <code><pre>
    public class Employee{
        public int EmpId { get; set; }
        public List<EmployeeProject> Projects { get; set; } }

    public class EmployeeProject{
        public DateTime UpdatedDate { get; set; }  }
    </pre></code>
    1st, nd 2 create a model for unwinded Project.
    <code><pre>
    public class UnwindEmployeeProject{
        public int EmpId { get; set; }
        public EmployeeProject Projects { get; set; }}
    </pre></code>

    </li><li>
    Full use of AggregateFluent
    <code><pre>
    var result = _db.GetCollection<Employee>("Employee")
                   .Aggregate()
                   .Unwind<Employee, UnwindEmployeeProject>(i => i.Projects)
                   .Group(
                       k => k.EmpId,
                       g => new
                       {
                           EmpId = g.Key,
                           LastUpdated = g.Max(x => x.Projects.LastUpdated)
                       })
                   .ToList();
    </pre></code>
    Full use of BSonDoc
    <code><pre>
    PipelineDefinition<Employee, BsonDocument> pipeline = new BsonDocument[]
    {
        new BsonDocument("$unwind", "$Projects"),
        new BsonDocument("$group",
            new BsonDocument
            {
                { "_id", "$EmpId" },
                { "LastUpdated",
                    new BsonDocument("$max", "$Projects.LastUpdated") }
            })
    };

    var result = _db.GetCollection<Employee>("Employee")
                    .Aggregate(pipeline)
                    .ToList(); 
    </pre></code>
    </li><li>
    The error <b>"No matching creator found"</b> most likely means that you received the server response, but the returned bson document cannot be converted into History or nested classes in this class.<br>
    So you should look at the proper serialization configuration. Try to avoid using dynamic classes in the projection
    </li><li>
    Q: How can <b>apply a group by to a result of another group</b> by using MongoDb?<br>
    Our type of grping but several joins, if nded chk <a href='https://stackoverflow.com/questions/54762166/how-can-apply-a-group-by-to-a-result-of-another-group-by-using-mongodb'>src</a>
    </li><li>
    (2 grps but uses <a href='https://stackoverflow.com/questions/51192252/mongodb-aggregate-group-on-inner-child-collection-and-get-count'>count</a>) MongoDB <b>aggregate group on inner child collection</b> and get count
    </li><li>
    *********GD example to play <a href='https://stackoverflow.com/questions/70081079/how-to-group-by-date-and-by-specific-field-in-mongodb'>with</a>
    </li><li>
    Using <b>$$ROOT</b> to bring in entire doc after <a href='http://docs.mongodb.org/manual/reference/operator/aggregation/group/#group-documents-by-author'>grping</a>
    </li><li>
    ****Aggregate & grp by <a href='https://stackoverflow.com/questions/69163990/mongodb-aggregate-and-group-by-subcategories-of-products'>subCategories</a>
    </li><li>
    *******<a href='https://stackoverflow.com/questions/50983522/mongoose-nested-group-by-with-sorting-on-nested-field'>Nested</a> grp w/sorting on nested fld: The 2nd grp nds to use _id from 1st grp, like so:
    <code><pre>
      $group: {
          _id: {
              Desc: "$Desc",...
      $group: {
          _id: "$_id.Desc",
    </pre></code>
    </li><li>
    Getting <a href='https://www.google.com/search?q=dotnet+mongodb+nested+groups+site%3Astackoverflow.com&safe=active&rlz=1C1GCEB_enUS991US1046&source=lnt&tbs=cdr%3A1%2Ccd_min%3A1%2F1%2F2015%2Ccd_max%3A2%2F25%2F2023&tbm=#ip=1'>nested</s> items
    </li><li>
    SO: <b>Group back unwinded array</b> after match stage and <a href='https://stackoverflow.com/questions/69009546/group-back-unwinded-array-after-match-stage-and-keep-the-parent-data-structure'>keep</a> the parent data/structure
    </li><li>
    Diff betw <a href='What is the actual difference between $project and $group?'>$project</s> & $group
    </li><li>
    (Uses lookup/group/<a href='https://stackoverflow.com/questions/65144585/how-to-group-the-same-fields-and-project-as-array-in-mongodb-aggregation'>push</a>)
    </li><li>
    using $replaceRoot after unwinding a match to get @ <a href='https://stackoverflow.com/questions/66913125/cant-unwind-documents-after-group'>nested</a> docs
    </li><li>
    The $group accumulator can be <a href='https://stackoverflow.com/questions/67516488/using-map-in-aggregate-group'>$arrayOfKeyValue</a> as below
    <code><pre>
        $group: {
          _id: "$arrayofkeyvalue.k",
          value: { $first: "$arrayofkeyvalue.v" }
        }
      },
      {
        $group: {
          _id: null,
          allkeysandvalues: { $push: { k: "$_id", v: "$value" } }
        }
    </li><li>
    Getting values from <a href='https://stackoverflow.com/questions/56617644/merging-two-stages-of-mongodb-aggregation-pipeline'>prior</a> stages
    </li><li>
    <b>Group by multiple flds</b>:
    The key to this is in the <a href='https://stackoverflow.com/questions/68979074/mongodb-aggregate-group-by-multiple-fields'>"_id" value</a> construction:
    <code><pre>
    IMongoCollection<BsonDocument> collection = GetYourCollectionHere();

    // there are many ways to create a filter. Using Builders here.
    var filter = Builders<BsonDocument>.Filter.Eq("SomeField", "ABC"); 

    var groupby = new BsonDocument("_id", new BsonDocument {
                            { "Gender", "$Gender" },
                            { "Age", "$Age" }
                    })
                    .Add("Min", new BsonDocument("$min", "$SomeParameter"))
                    .Add("Max", new BsonDocument("$max", "$SomeParameter"));

    var result = collection
                    .Aggregate()
                    .Match(filter)
                    .Group(groupby);
    </pre></code>
    </li><li>
<b>Basic Grouping</b>:
When you use the $group stage in aggregation you learn to group by one field as such:<br> { $group: { "_id": "$field1"...<br>
When you want to group by two or more fields "_id" needs to be a subdocument and you pass the fields as key value pairs inside the subdocument as such:
<code><pre>
{      $group: { "_id": { "product1": "$product1", "product2": "$prod..
</pre></code>
    </li><li>
<b>Using $sum</b><br>
<code><pre>
"total_orders": {"$sum": 1},
  {
    "$set": {
      "doc_Count": {
        "$sum": 1
      },
    }
  },
</pre></code>
    </li><li>
<b>Using $set</b><br>
<code><pre>
  // Set (new fld) product id to be the value of the field that was grouped on
  {"$set": {
    "product_id": "$_id",
  }},

  // Omit unwanted fields
  {"$unset": [
    "_id",
  ]}, 
</pre></code>
    </li><li>
<b>Using includeArrayIndex (count)</b><br>
https://stackoverflow.com/questions/60835306/mongodb-add-counter-to-each-retrieved-document
<code><pre>
  {
    $group: {
      _id: null,
      data: {
        $push: "$$ROOT"
      }
    }
  },
  {
    $unwind: {
      path: "$data",
      includeArrayIndex: "counter",
      
    }
  },
  {
    $replaceRoot: {
      newRoot: {
        $mergeObjects: [
          "$data",
          {
            counter: {
              $add: [
                "$counter",
                1
              ]
            }
          }
        ]
      }
    }
  },
</pre></code>
    </li><li>
<b>Group by mult flds</b><br>
SO <a href='https://stackoverflow.com/questions/22932364/mongodb-group-values-by-multiple-fields'>qn</a>
    </li><li>

<b>Using project to grp by nested array</b><br>
(<a href='https://mongoplayground.net/p/az6rekfZWTn'>Playground</a> snippet, contains link to SO Qn)
    </li><li>
<b>Using $addFields to add to an existing array</b><br>
You can use $addFields with a $concatArrays expression to add an element to an existing array field. (see @ bottom of <a href='https://www.mongodb.com/docs/manual/reference/operator/aggregation/addFields/#mongodb-pipeline-pipe.-addFields'>manPg</a>)
    </li><li>


    Recent Aggregation <a href='https://www.google.com/search?q=dotnet+mongodb+aggregation+examples&rlz=1C1GCEB_enUS991US1046&source=lnt&tbs=cdr%3A1%2Ccd_min%3A1%2F1%2F2018%2Ccd_max%3A2%2F25%2F2023&tbm=#ip=1'>examples</a> in .net

    </li></ul>

    Related:
    <ul><li>
    Using <a href='https://www.bmc.com/blogs/mongodb-projection-operators/'>$meta</a> (txtScore)
    </li><li>
    QkUpd: Using switch & updateMany to update sev. docs <a href='https://www.percona.com/blog/mongodb-modifying-documents-using-aggregation-pipelines-and-update-expressions/'>@ once</a>
    </li><li>
    Exhaustive <a href='https://www.red-gate.com/simple-talk/development/dotnet-development/how-to-program-with-mongodb-using-the-net-driver/'>walkthrough</a> w/serialization et al
    </li><li>
    <a href='https://kevsoft.net/2020/01/27/paging-data-in-mongodb-with-csharp.html'>Paging</a> data
    </li><li>
    <a href='https://stackoverflow.com/questions/70511817/c-sharp-mongo-paging-with-aggregates'>Paging</a> w/aggregation
    </li></ul>
  
    <hr>
    <details>
    <summary><span class='mHG'>aggregation $group does not order its output documents</span></summary>
    See aggregation group <a href='http://docs.mongodb.org/manual/reference/operator/aggregation/group/'>doc</a>
    <hr>
    </details>
    <br>
    <details>
    <summary><span class='mHG'>aggregation $limit</span></summary>
    $limit limits the number of processed elements of an immediately preceding $sort operation, not only the number of elements passed to the next stage. See the note <a href='http://docs.mongodb.org/manual/reference/operator/aggregation/limit/doc'> here</a>
    <hr>
    </details>
    <br>
    <details>
    <summary><span class='mHG'>aggregation pagination on grp data</span></summary>
    In $group items you can't directly apply pagination, but below trick will be used ,<br>step 1 - write aggregation on product table, and write groupBY<br>step 2 - prdSkip for skipping , and limit for limiting data , pass it dynamically<br>finally query looks like - params - limit , skip - for category pagination and prdSkip and PrdLimit for products pagination<br>
    <code><pre>db.products.aggregate([<br>        { $group: { _id: '$prdCategoryId', products: { $push: '$$ROOT' } } },<br>        {<br>            $lookup: {<br>                from: 'categories',<br>                localField: '_id',<br>                foreignField: '_id',<br>                as: 'categoryProducts',<br>            },<br>        },<br>        {<br>            $replaceRoot: {<br>                newRoot: {<br>                    $mergeObjects: [{ $arrayElemAt: ['$categoryProducts', 0] }, '$$ROOT'],<br>                },<br>            },<br>        },<br>        {<br>            $project: {<br>                // pagination for products<br>                products: {<br>                    $slice: ['$products', prdSkip, prdLimit],<br>                },<br>                _id: 1,<br>                catName: 1,<br>                catDescription: 1,<br>            },<br>        },<br>    ])<br>    .limit(limit) // pagination for category<br>    .skip(skip);
    </pre></code><br>answered Oct 22 '20 at 6:50	Akshay Dhawle
    <hr>
    </details>
</details>  <!--aggregation-->
<p>
<p>
<details>
<summary><span class='mHG'>query{}</span></summary>
                      

    <details>
    <summary><span class='mHG'>F# Repo Query Src</span></summary>

    <ul>
    <li>FSharp.Core.<a href='https://github.com/dotnet/fsharp/blob/889709d8e506e6b707c6eaec5c310edda9c2be65/src/FSharp.Core/Query.fs'>Query.fs</a> contains module Query
    <br>tys QuerySource/<a href='https://github.com/dotnet/fsharp/blob/285fb61e0befe965b5626d5e009fd1ebd5189084/src/FSharp.Core/Query.fs#L52'>QryBuilder</a>
    <br>MakeGroupBy, MakeOrderBy, MakeSkip...
    <br>let (|CallGroupBy|_|)... + 
    <br>line 1272 on contains ALL QryPattns + 
    <br>line 1791 let EliminateNestedQueries q: elimates query{ ... query{}...})</li>

    <li>fsharp.tools.eval.<a href='https://github.com/dotnet/fsharp/blob/faa115a2dfd446d2d83ba6dfe19e92a5cc5e13f6/tests/fsharp/tools/eval/test.fsx'>test.fsx</a> contains modules QuotationEvaluation, EvaluationTests, Query(some patterns here)</li>

    <li>Expressions/DataExpressions/QueryExpressions/<a href='https://github.com/dotnet/fsharp/blob/dbf9a625d3188184ecb787a536ddb85a4ea7a587/tests/fsharpqa/Source/Conformance/Expressions/DataExpressions/QueryExpressions/FunctionAsTopLevelLet01.fs'>FunctionAsTopLevelLet01.fs</a> contains Various ways of defining functions as a top level let in queries, e.g.<br>
    <code><pre>
    query { for i in ds do
            let add3 = add 3
            select (add3 i)}
    </pre></code></li>

    <li>DataExpressions/QueryExpressions/<a href='https://github.com/dotnet/fsharp/blob/dbf9a625d3188184ecb787a536ddb85a4ea7a587/tests/fsharpqa/Source/Conformance/Expressions/DataExpressions/QueryExpressions/MatchInQuery01.fs'>MatchInQuery01.fs</a> as above, but for matches, e.g.<br>
    <code><pre>
    query { for i in ds do
            let x = 
                match (i % 2) with
                | 0 -> i
                | _ -> i * i
            select x}
    </pre></code></li>

    <li>DataExpressions/QueryExpressions/<a href='https://github.com/dotnet/fsharp/blob/dbf9a625d3188184ecb787a536ddb85a4ea7a587/tests/fsharpqa/Source/Conformance/Expressions/DataExpressions/QueryExpressions/MatchInQuery02.fs'>MatchInQuery02.fs</a> as above, but using function | for matches</li>

    <li>DataExpressions/QueryExpressions/<a href='https://github.com/dotnet/fsharp/blob/dbf9a625d3188184ecb787a536ddb85a4ea7a587/tests/fsharpqa/Source/Conformance/Expressions/DataExpressions/QueryExpressions/FunctionsDefinedOutsideQuery01.fs'>FunctionsDefinedOutsideQuery01.fs</a> e.g.<br>
    <code><pre>
    let ie = [1;2;3;4;5]
    let q3 (ds : seq<int>) =    query {   for i in ds do
                                          select (add i i)
                                      } |> Seq.toList
    if q3 ie <> [2;4;6;8;10] then printfn "q3 failed"; exit 1
    </pre></code></li>

    <li>DataExpressions/QueryExpressions/<a href='https://github.com/dotnet/fsharp/blob/dbf9a625d3188184ecb787a536ddb85a4ea7a587/tests/fsharpqa/Source/Conformance/Expressions/DataExpressions/QueryExpressions/FunctionWithinTopLevelLet01.fs'>FunctionWithinTopLevelLet01.fs</a> e.g.<br>
    <code><pre>
    let q1 (ds : seq<int>) =    query { for i in ds do
                                        let aFunc =
                                           let f x = x + 1
                                           f
                                        select (aFunc i)    }
    </pre></code></li>

    <li><a href='fsharp/core/queriesCustomQueryOps/test.fsx'>test.fsx</a> has module ShapesOfQueryQuotations which contains several patterns + some more interesting stuff incl evenBldrs/Distributions/etc., all as CEs...</li>

    <li><a href='https://github.com/dotnet/fsharp/blob/ef9d1aa7cb6edc6c80fb637065afdf8dc0b0bf6c/src/FSharp.Core/Query.fsi'>Query.fsi</a>
    (For Reference) Library functionality for F# query syntax and interoperability with .NET LINQ Expressions</li>
    <li>
Tests: <a href='https://github.com/dotnet/fsharp/blob/main/tests/fsharp/core/queriesOverIQueryable/test.fsx'>queriesOverIQueryable</a>/test.fsx:
<br>~2500 lines, allows:
    <code><pre>
    let data = [Customer]
    let db = System.Linq.Queryable.AsQueryable<Customer>(data |> Seq.ofList)
    </pre></code>
    line <a href='https://github.com/dotnet/fsharp/blob/285fb61e0befe965b5626d5e009fd1ebd5189084/tests/fsharp/core/queriesOverIQueryable/test.fsx#L1291'>1291</a>
    <br>    // Smoke test for returning an object using property-set notation for member init
    <br>ie, query in below line returns C2 ty w/vals populated
    <code><pre>
    (query { for x in db do yield C2(V1=1, V2=2) } 
    |> qmap (fun r -> r.V1, r.V2)) 
...
       (query { for p in db do
                groupBy p.Name into g
                let s = query { for a in g do sumByNullable a.SomeNullableInt16Value }
                select (g.Key, s) })
    </pre></code>
Note: The above file uses Lists (Queryable); below uses Seq (IEnumerable) (note makes little sense out of ctxt but retained for the diff betw the two...)
    </li>
<li>
MANY patterns in CustomQryOps <a href='https://github.com/dotnet/fsharp/blob/main/tests/fsharp/core/queriesCustomQueryOps/test.fsx'>here</a>, incl 
/// Detect a call to 
    <code><pre>
      query.Run
      query { ... }
      query.For
      yield
      for .. in do yield x
    </pre></code>
  </li>    
    </ul>
    </details>
</details>
    <p>
      
    <details>
    <summary><span class='mHG'>Filter/Find/RegEx/Bldr</span></summary>
    <a href='https://stackoverflow.com/questions/66966567/how-to-filter-regular-expression-in-mongodb-with-f'>Regex</a> Filters in Mongo
    <br>
    Brian Berns:  You're close. The only problem I see is that the LINQ expression has to have a return type of Object. This happens implicitly in C#, but in F# you have to explicitly cast it:
    <code><pre>
    let filter1 =
        Builders<PostDataItem>
            .Filter
            .Regex(
                (fun n -> n.reference1 :> obj),
                BsonRegularExpression("1002\d{5}"))
    </pre></code>
    (IMHO, this is just a bit of C# bias baked into their API. Hopefully they’ll fix it one day.)
    <hr>
    Another similar <a href='https://stackoverflow.com/questions/67101596/how-to-specify-field-mongodb-definition-dynamically-using-a-string-in-f'>filter</a> bld (one fld is a BSonDoc):<br>
    <code><pre>
    let coll: IMongoCollection<NZPostDataItem> = MongoUtil.getNzpostCollection()
    let filter = Builders<NZPostDataItem>.Filter.And(
            Builders<NZPostDataItem>.Filter.Gte((fun n -> n.dateLodged),DateTime(2020,10,1)),
            Builders<NZPostDataItem>.Filter.Eq((fun n -> n.eshipMatched.Value) , true)
    )// ... etc 
    </pre></code>
    <hr>
    Using <a href='https://stackoverflow.com/questions/51835975/f-mongodb-using-find-with-string-filter'>Find</a> w/string filter
    <hr>
    gd c# <a href='https://stackoverflow.com/questions/51990950/getting-general-information-about-mongodb-collections-with-fsharp'>pipeline</a> (project, unwind, grp) impl: 
    <hr>
    <a href='https://stackoverflow.com/questions/64723616/projecting-results-from-mongodb-find-in-f'>Projecting</a> results from MongoDb Find
    <hr></details>
<p>

<details>
<summary><span class='mHG'>2.12.22: Pagination in mongoDb Collections</span></summary>
<br>MPT note: IF NECC this approach can be used by 
<br>	- adding a new tmp Counter field *AFTER GROUPING*
<br>	- finding the range#s as above; then getting the pg.
<br>
<br>SO post: <b>When talking about pagination in MongoDB, it is easily to write this code: </b>
<br>
<br>collection.find().skip(pageSize*(pageNum-1)).limit(pageSize);
<br>Above is the native solution supported by MongoDB, but this is not efficient if there are huge documents in the collection. Suppose you have 100M documents, and you want to get the data from the middle offset(50Mth). MongoDB has to build up the full dataset and walk from the beginning to the specified offset, this will be low performance. As your offset increases, the performance keeps degrade.
<br>
<br>The root cause is the skip() command which is not efficient and can not take big benifit from index.
<br>
<br>Below is another solution to improve performance on large data pagination:
<br>
<br>The typical usage scenario of pagination is that there is a table or list to show data of specified page, and also a 'Previous Page' & 'Next Page' button to load data of previous or next page.
<br>
<br>If you got the '_id' of the last document in current page, you can use find() instead of skip(). Use _id > currentPage_LastDocument._id as one of the criteria to find next page data. Here is pseudocode:
<br>
<br>//Page 1
<br>collection.find().limit(pageSize);
<br>//Get the _id of the last document in this page
<br>last_id = ...
<br>
<br>//Page 2
<br>users = collection.find({'_id': {$gt: last_id}}).limit(pageSize);
<br>//Update the last id with the _id of the last document in this page
<br>last_id = ...
<br>This will avoid MongoDB to walk through large data when using skip().
<br>
<br>edited Jun 4 '19 at 12:17
<br>SQB answered May 10 '18 at 6:47
<br>
<br>
<hr></details>



<hr>
<b>mattpodwysocki</b>/MongoDB and <a href='https://gist.github.com/mattpodwysocki/218388'>F# gist
<br>
fssnip: Basic <a href='http://www.fssnip.net/7Xm/title/Idiomatic-F-wrapper-for-storing-and-reading-from-MonoDB'>wrapper</a> for storing and reading docs from MongoDB with .NET.
<br>
<a href='https://www.w3resource.com/mongodb-exercises/'>Exercises</a> 
<br>
<a href='https://github.com/ramnes/awesome-mongodb'>Awesome</a> MongoDb<br>
<hr>

<p>
<details>
<summary><span class='mHG'>Libs</span></summary>
tkellogg/<a href='https://github.com/tkellogg/MongoDB.FSharp'>MongoDB.FSharp</a>
Silent utilities to make the official MongoDB driver feel natural to work with in F#
(many forks but not updated 8 yrs)
<br>
<a href='https://github.com/MNie/BagnoDB'>BagnoDb</a>: F# wrapper for MongoDB
; lotsa goodies (only filter tho gd.; uses Svenson.unqt)
<br>
<a href='https://github.com/AngelMunoz/Mondocks'>Mondocks</a>: Maintained upto 2 yrs ago; provides a DSL allowing creatn of MongoDB Commands (raw queries)
            <BR><a href='https://github.com/ctaggart/froto'>Froto (protoBuffs)</a>
            <BR><a href='https://github.com/gothinkster/fsharp-realworld-example-app'> Db app (Suave + Mongo)</a>
            <BR><a href='https://github.com/jet/falanx'>Falanx</a> by jet.com (now wm): Code generation from Protobuf v3 schema (rather than types being injected as a type provider.)
<hr>
</details>
<p>
<details>
<summary><span class='mHG'>Capacity planning</span></summary>
Additional capacity can be added with no application downtime, and you can optionally <br>enable <a href='https://docs.atlas.mongodb.com/cluster-autoscaling/'>auto-scaling</a> to respond automatically to spikes in usage.<br><br>Ensuring that applications gracefully handle cluster failover through <a href='Ensuring that applications gracefully handle cluster failover through testing.'>testing.</a>
</details>
<p>
<details>
<summary><span class='mHG'>MongoDB Indexing</span></summary>
<br>"ALL indexes shd fit in memory"<br>If your index doesnt fit in memory the slow down you will experience when querying on that index as pages are read from disk expired and then reread from disk will be dramatic.<br><br>The goal for every performant database is to have all its regularily queried indexes to fit completely in RAM. To futher increase performance the most regularily queried records should fit in RAM as well.<br><br>For a gaming application this means data associated with logged in users, for a banking application accounts that have transactions in the last thirty days etc. etc.<br><br>...from mongoDevBlog related to above, how to fit all idx es into RAM...<br>In MongoDB Collections and Indexes both use the same underlying data structure. WiredTiger tables - these are BTrees (B+ ish trees) , essentially key-value stores arranged into pages(or blocks depending who you ask) - each page is 32KB in size or one entry whichever is larger (Up to 16MB for a single 16MB BSON document) - its then compressed when flushed to disk. In memory a collection page contains both the the on-disk version of the page as well as a list of changes to any document not yet reconciled to disk. An Index page contains the index keys and for each key (which may be the full key or prefix compressed) a pointer to the identity of the document it points to.<br><br>When you access an index - MongoDB checks to see if the page is in cache - if not it reads it from the disk (going via the OS pagecache so it may be cached there) - index pages are not compressed on disk as they already have prefix compression.<br><br>The upshot is that each index lookup may in cache (nice and fast) or not in which case , nothing to do with page faults - this is all explicitly tracked, it will require a disk read which will be 32KB and a seek at the very least - if you have readahead set appropriately it may be more than 32KB. If that happens to be in your OS page cache it will be quicker but it still needs some processing to put it in cache. The seek will take 1 IO operation at least so a 1000 IOPS disk, with random seeks in an index which is much larger than ram will be very much throttled by IO.<br><br>You can look at the Read-Into-Cache metric using any of the MongoDB tooling (or look in db.serverStatus() and diff the entries) you can also observer the cache for collections and indexes using mongocacheview.js (https://github.com/johnlpage/MongoCacheView).<br><br>In general - if your working set does not fit in ram, expect one to two orders of magnitude slower operations that hit those keys (queries, inserts, deletes, updates of indexed values) , consider (a) Adding RAM (b) Making indexes smaller  Adding many IOPS - in that order.<br><br>...also...<br>If you want to preheat (upload it into RAM) your indexes when mongod start you may use db.runCommand({"touch" : <collection name>, "data" : true, "index" : true}). Accessing index entries that are not in memory is particularly inefficient, as it often causes two page faults. There is one fault to load the index entry into memory and then another to load the document into memory. When an index lookup causes a page fault its called a btree miss. MongoDB also tracks btree hits: when an index access does not have to go to disk (from MongoDB definitive guide).  Alexey Smirnov Dec 31 '16 at 12:36<br><br>>>$or query using more than 2 indexes takes forever	Joris_SEBIRE<br>Hello,	I have a probleme with a mongo query that uses an $or like :<br>{<br>    a: 1,<br>    b: 2,<br>    $or: [<br>        { c: 3 },<br>        { d: 4 },<br>        { e: 5 },<br>        { f: 6 }<br>    ]<br>}<br>i have every a_b_c, a_b_d, a_b_e and a_b_f indexes but that query takes more than 150 seconds.<br>But, if i comment any 2 of the 4 items in my $or, the request takes 0.5 seconds<br>Does mongo applie a limit of index used in an $or query ? or something i didnt get ?<br>Thanks for your answer.<br><br>Pavel_Duchovny MongoDB Employee<br>Welcome to MongoDB community.<br>The ways your indexes are built the engine tries to do an index intersection loading all indexes to memory and merging them.<br>I think that for this query its best to use either all fields in one index or just index a,b <br>Thanks,<br>Pavel<br><br>Sudhesh_Gnanasekaran<br>Refer to this documentation that might be helpful for your use-case.<br>https://docs.mongodb.com/manual/core/index-compound/<br>,...from above...MongoDB imposes a limit of 32 fields for any compound index.<br>Compound indexes can support queries that match on multiple fields.<br>...Index fields are parsed in order; if a query omits a particular index prefix, it is unable to make use of any index fields that follow that prefix.<br><br>...The choice between creating compound indexes that support your queries or relying on index intersection depends on the specifics of your system. (see https://docs.mongodb.com/manual/core/index-intersection/#index-intersection-compound-indexes)<br><br>MongoDB may use the same wildcard index for satisfying each independent argument of the query $or or aggregation $or operators.<br><br>if you want the aggregation to use the index you need to perform either a $match or $sort stages in the beginning of the query.<br>eg,  db.collection.aggregate([{$match:{"Instance.field":"value"},<br>	{$unwind: "$Instance"},<br>	{$match:{"Instance.field":"value"}}])<br><br>https://stackoverflow.com/questions/8607637/are-there-any-tools-to-estimate-index-size-in-mongodb<br>mongodb query and index optimization.<br>
<br>
<hr></details>
<p>
2.12.22: <a href='https://www.infoq.com/articles/Starting-With-MongoDB/'>14 gotchas for MongoDB</a>
<p>

<hr>
<details>
<summary><span class='mHG'>Other DocDbs</span></summary>

            <BR><a href='https://github.com/Dzoukr/CosmoStore'> MSFT Cosmo</a>
<hr>
DocDb vs Cosmos vs Mongo <a href='https://db-engines.com/en/system/Amazon+DocumentDB%3BMicrosoft+Azure+Cosmos+DB%3BMongoDB'>comparision</a>
<br>
<ul><li>AMZN DocDb + Cosmos offer MongoDB compatible JSON APIs)</li>
<li>DocDb has no .net support (Go/Java/Node/Py)</li></ul>

<br>DocDb <a href='https://db-engines.com/en/ranking/document+store'>ranking</a>

<br>CouchDB's db <a href='https://couchdb.apache.org/fauxton-visual-guide/index.html#_activetasks'>setup views</a> (sorta similar to Masala)
<br>
<h3>To Check:</h3>
<ul>
<li>Amazon DynamoDB detailed information</li>
<li>Couchbase</li>
<li>CouchDB</li>
<li>Google Cloud Firestore</li>
<li>IBM Cloudant</li>
<li>Oracle NoSQL</li></ul>
<hr></details>
                    </div>
                </section>
                <!--dev/F#/F_Db content-->
